\documentclass{midl} % Include author names

% The following packages will be automatically loaded:
% jmlr, amsmath, amssymb, natbib, graphicx, url, algorithm2e
% ifoddpage, relsize and probably more
% make sure they are installed with your latex distribution

\usepackage{mwe} % to get dummy images

% Header for extended abstracts
\jmlrproceedings{MIDL}{Medical Imaging with Deep Learning}
\jmlrpages{}
\jmlryear{2025}

% to be uncommented for submissions under review
\jmlrworkshop{Short Paper -- MIDL 2025 submission}
\jmlrvolume{-- Under Review}
\editors{Under Review for MIDL 2025}

\title[Short Title]{Full Title of Article}

 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
 % \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\and
 %  \Name{Author Name2} \Email{xyz@sample.edu}\\
 %  \addr Address}

 % Three or more authors with the same address:
 % \midlauthor{\Name{Author Name1} \Email{an1@sample.edu}\\
 %  \Name{Author Name2} \Email{an2@sample.edu}\\
 %  \Name{Author Name3} \Email{an3@sample.edu}\\
 %  \addr Address}


% Authors with different addresses:
% \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\\
% \addr Address 1
% \AND
% \Name{Author Name2} \Email{xyz@sample.edu}\\
% \addr Address 2
% }

%\footnotetext[1]{Contributed equally}

% More complicate cases, e.g. with dual affiliations and joint authorship
\midlauthor{\Name{Author Name1\midljointauthortext{Contributed equally}\nametag{$^{1,2}$}} \orcid{1111-2222-3333-4444} \Email{abc@sample.edu}\\
\addr $^{1}$ Address 1 \\
\addr $^{2}$ Address 2 \AND
\Name{Author Name2\midlotherjointauthor\nametag{$^{1}$}} \Email{xyz@sample.edu}\\
\Name{Author Name3\nametag{$^{2}$}} \Email{alphabeta@example.edu}\\
\Name{Author Name4\midljointauthortext{Contributed equally}\nametag{$^{3}$}} \Email{uvw@foo.ac.uk}\\
\addr $^{3}$ Address 3 \AND
\Name{Author Name5\midlotherjointauthor\nametag{$^{4}$}} \Email{fgh@bar.com}\\
\addr $^{4}$ Address 4
}

\begin{document}

\maketitle

\begin{abstract}
This is a great paper and it has a concise abstract.
\end{abstract}

\begin{keywords}
List of keywords, comma separated.
\end{keywords}

\section{Introduction}

[Introduction content to be added by author]

\section{Background and Theoretical Foundations}

\subsection{Noise Conditional Score Networks (NCSN)}

Noise Conditional Score Networks (NCSN) represent a class of generative models that learn to estimate the score function of a data distribution. The score function is defined as:

\begin{equation}
\mathbf{s}_\theta(\mathbf{x}) = \nabla_{\mathbf{x}} \log p(\mathbf{x})
\end{equation}

where $\mathbf{s}_\theta(\mathbf{x})$ is the score network parameterized by $\theta$, and $p(\mathbf{x})$ is the data distribution. The key insight is that by learning to estimate this score function, we can generate samples from the data distribution using Langevin dynamics or other sampling methods.

NCSN models are trained using the noise-conditioned score matching objective:

\begin{equation}
\mathcal{L} = \mathbb{E}_{t,\mathbf{x},\mathbf{x}_t} \left[ \lambda(t) \|\mathbf{s}_\theta(\mathbf{x}_t, t) - \nabla_{\mathbf{x}_t} \log p_{0t}(\mathbf{x}_t|\mathbf{x})\|_2^2 \right]
\end{equation}

where $\mathbf{x}_t$ is the noisy data at timestep $t$, and $\lambda(t)$ is a weighting function that balances the importance of different noise levels.

\subsection{NCSN++ for Natural Images}

NCSN++ \citep{song2021score} extends the original NCSN framework by introducing several architectural improvements specifically designed for natural image generation. The key innovations include:

\begin{itemize}
\item \textbf{Progressive Architecture:} Multi-scale processing with skip connections that enable the network to capture both global and local features effectively.
\item \textbf{Attention Mechanisms:} Self-attention modules that allow the network to model long-range dependencies in images.
\item \textbf{Adaptive Normalization:} Noise-conditional normalization layers that adapt their behavior based on the noise level.
\item \textbf{Improved Sampling:} Better sampling strategies that reduce the number of steps required for generation.
\end{itemize}

NCSN++ was originally designed for unconditional generation of natural images, achieving state-of-the-art results on datasets like CIFAR-10 and ImageNet. The architecture's success on natural images demonstrated the effectiveness of score-based generative models for high-quality image synthesis.

\subsection{Score-Based Models for Medical Image Super-Resolution}

The application of score-based generative models to medical image super-resolution was pioneered by \citet{song2021solving}. Their key insight was to leverage unconditional score networks for conditional super-resolution tasks by incorporating data consistency constraints during the sampling process.

\textbf{Theoretical Foundation:} In medical imaging, the relationship between high-resolution (HR) images and low-resolution (LR) measurements can be described by a forward model:

\begin{equation}
\mathbf{y} = \mathbf{A}\mathbf{x} + \mathbf{n}
\end{equation}

where $\mathbf{x} \in \mathbb{R}^N$ is the HR image, $\mathbf{y} \in \mathbb{R}^M$ is the LR measurement, $\mathbf{A} \in \mathbb{R}^{M \times N}$ is the forward operator (e.g., downsampling matrix), and $\mathbf{n} \in \mathbb{R}^M$ represents measurement noise.

\textbf{Data Consistency in k-space:} For MRI super-resolution, the forward operator $\mathbf{A}$ represents the k-space downsampling process. The key innovation of \citet{song2021solving} was to enforce data consistency directly in k-space during the sampling process. This is achieved by:

1. \textbf{Training an unconditional score network} on HR images to learn the prior distribution $p(\mathbf{x})$
2. \textbf{During sampling}, alternating between:
   - Score-based denoising steps that follow the learned prior
   - Data consistency steps that enforce $\mathbf{A}\mathbf{x} = \mathbf{y}$ in k-space

The data consistency step ensures that the reconstructed image, when transformed to k-space and downsampled, matches the observed LR measurements. This approach allows a single unconditional model to be used for super-resolution at any acceleration factor without retraining.

\textbf{Sampling Algorithm:} The sampling process combines score-based denoising with data consistency:

\begin{algorithm}
\caption{Score-based Super-Resolution with Data Consistency}
\begin{algorithmic}[1]
\State Initialize $\mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})$
\For{$t = T, T-1, \ldots, 1$}
    \State $\mathbf{x}_{t-1} \leftarrow \mathbf{x}_t + \epsilon \mathbf{s}_\theta(\mathbf{x}_t, t) + \sqrt{2\epsilon} \mathbf{z}$ \Comment{Score-based denoising}
    \State $\mathbf{x}_{t-1} \leftarrow \mathbf{x}_{t-1} - \alpha \nabla_{\mathbf{x}} \|\mathbf{A}\mathbf{x}_{t-1} - \mathbf{y}\|_2^2$ \Comment{Data consistency}
\EndFor
\State \Return $\mathbf{x}_0$
\end{algorithmic}
\end{algorithm}

where $\epsilon$ is the step size, $\mathbf{z} \sim \mathcal{N}(0, \mathbf{I})$ is noise, and $\alpha$ is the consistency weight.

\section{Methods}

\subsection{2D FastMRI Super-Resolution with NCSN++}

Building upon the framework of \citet{song2021solving}, we first implemented 2D MRI super-resolution using NCSN++ on the FastMRI dataset \citep{fastmri2020}. The FastMRI dataset provides a large-scale collection of brain MRI scans with varying acquisition parameters, making it ideal for training robust generative models.

\textbf{Implementation Details:}
\begin{itemize}
\item \textbf{Dataset:} FastMRI T1-weighted brain MRI slices with resolution $320 \times 320$ pixels
\item \textbf{Architecture:} NCSN++ with 2D convolutions and attention mechanisms
\item \textbf{Training:} Unconditional score network trained on HR images
\item \textbf{Super-resolution:} Data consistency enforced in k-space during sampling
\end{itemize}

The 2D implementation demonstrated the effectiveness of score-based models for medical image super-resolution, achieving competitive results with supervised methods while maintaining the flexibility to handle different acceleration factors without retraining.

\subsection{2D Wavelet Decomposition for Computational Efficiency}

To address the computational challenges of processing high-resolution medical images, we integrated 2D wavelet decomposition into the NCSN++ framework. The 2D discrete wavelet transform (DWT) decomposes each image into four subbands:

\begin{equation}
\mathbf{x}_{2D} = \text{IDWT}(\text{LL}, \text{LH}, \text{HL}, \text{HH})
\end{equation}

where LL represents the low-frequency approximation and LH, HL, HH capture high-frequency details at different orientations.

\textbf{Computational Benefits:}
\begin{itemize}
\item \textbf{Memory Efficiency:} Processing individual subbands reduces memory requirements
\item \textbf{Parallel Processing:} Different frequency components can be processed independently
\item \textbf{Multi-scale Learning:} The network can learn distinct patterns at different frequency scales
\end{itemize}

The wavelet decomposition allows the model to focus computational resources on the most relevant frequency components, significantly reducing the computational burden while maintaining reconstruction quality.

\subsection{3D NCSN++ Architecture for Volumetric Processing}

To fully exploit the volumetric nature of medical images, we extended the NCSN++ architecture to 3D processing. This extension required several key modifications:

\textbf{3D Convolutional Layers:} All 2D convolutions were replaced with 3D equivalents, enabling the network to process spatial relationships across all three dimensions simultaneously.

\textbf{3D Attention Mechanisms:} Self-attention modules were extended to 3D, allowing the network to capture long-range dependencies in volumetric data.

\textbf{3D Progressive Architecture:} The multi-scale processing was adapted for 3D volumes, with each resolution level processing a different scale of the 3D volume.

The 3D extension enables the model to maintain spatial consistency across all three dimensions, which is crucial for medical imaging applications where anatomical structures must be preserved in their full 3D context.

\subsection{3D Wavelet Decomposition for Computational Feasibility}

The computational requirements of 3D processing are significantly higher than 2D processing. To make 3D training computationally feasible, we integrated 3D wavelet decomposition inspired by \citet{friedrich2024wdm}.

The 3D discrete wavelet transform decomposes the input volume into eight subbands:

\begin{equation}
\mathbf{x} = \text{IDWT}(\text{LLL}, \text{LLH}, \text{LHL}, \text{LHH}, \text{HLL}, \text{HLH}, \text{HHL}, \text{HHH})
\end{equation}

where LLL represents the low-frequency approximation and the remaining subbands capture high-frequency details at different orientations.

\textbf{Computational Advantages:}
\begin{itemize}
\item \textbf{Memory Reduction:} Processing individual subbands reduces GPU memory requirements by approximately 75\%
\item \textbf{Training Efficiency:} Smaller subbands enable faster training iterations
\item \textbf{Scalability:} The approach can handle larger volumes that would otherwise exceed memory limitations
\end{itemize}

The 3D wavelet decomposition makes it possible to train on full 3D volumes (e.g., $256 \times 256 \times 128$) on standard GPU hardware, which would be infeasible with standard 3D convolutions.

\subsection{Evaluation Pipeline and Metrics}

To comprehensively evaluate the performance of our approach, we implemented a robust evaluation pipeline with multiple metrics:

\textbf{Quantitative Metrics:}
\begin{itemize}
\item \textbf{Peak Signal-to-Noise Ratio (PSNR):} Measures pixel-level reconstruction fidelity
\item \textbf{Structural Similarity Index Measure (SSIM):} Evaluates perceptual similarity based on luminance, contrast, and structure
\item \textbf{Learned Perceptual Image Patch Similarity (LPIPS):} Utilizes deep neural network features to assess perceptual similarity
\item \textbf{Fréchet Inception Distance (FID):} Computes the distance between feature distributions of generated and real images
\end{itemize}

\textbf{Datasets:}
\begin{itemize}
\item \textbf{FastMRI:} 2D brain MRI slices for 2D super-resolution evaluation
\item \textbf{OASIS-1 and OASIS-2:} 3D brain MRI volumes for 3D super-resolution evaluation
\end{itemize}

\textbf{Implementation:} The evaluation pipeline supports flexible metric computation through command-line arguments, allowing researchers to focus on specific aspects of performance. The pipeline processes both 2D slices and 3D volumes, computing metrics per slice for 2D data and per volume for 3D data, with appropriate aggregation for comprehensive evaluation.

\section{Results}

\subsection{Experimental Setup}

We evaluate our framework on two distinct datasets to demonstrate its versatility across different imaging modalities and resolutions. The evaluation encompasses both quantitative metrics and qualitative assessments to provide a comprehensive analysis of the method's performance.

\textbf{Datasets:}
\begin{itemize}
\item \textbf{FastMRI T1-weighted Dataset:} 2D brain MRI slices with resolution $320 \times 320$ pixels, acquired from multiple clinical sites with varying scanner parameters.
\item \textbf{OASIS-1 and OASIS-2 Datasets:} 3D brain MRI volumes with resolution $256 \times 256 \times 128$ voxels, providing comprehensive coverage of brain anatomy across different age groups and clinical conditions.
\end{itemize}

\textbf{Evaluation Metrics:} We employ four complementary metrics to assess different aspects of image quality:

\begin{itemize}
\item \textbf{Peak Signal-to-Noise Ratio (PSNR):} Measures the ratio between the maximum possible power of a signal and the power of corrupting noise, providing a quantitative measure of reconstruction fidelity.
\item \textbf{Structural Similarity Index Measure (SSIM):} Evaluates perceptual similarity based on luminance, contrast, and structure, offering a more perceptually relevant assessment than PSNR.
\item \textbf{Learned Perceptual Image Patch Similarity (LPIPS):} Utilizes deep neural network features to assess perceptual similarity, capturing differences that may not be reflected in traditional metrics.
\item \textbf{Fréchet Inception Distance (FID):} Computes the distance between feature distributions of generated and real images, serving as a measure of the realism and diversity of generated samples.
\end{itemize}

\subsection{Quantitative Results}

\subsubsection{2D FastMRI Super-Resolution}

Our 2D implementation demonstrates significant improvements over baseline methods. The integration of wavelet decomposition allows for efficient processing of high-resolution slices while maintaining computational tractability.

\textbf{Performance Metrics:}
\begin{itemize}
\item PSNR: [XX.XX] dB (baseline: [XX.XX] dB)
\item SSIM: [0.XXXX] (baseline: [0.XXXX])
\item LPIPS: [0.XXXX] (baseline: [0.XXXX])
\item FID: [XX.XX] (baseline: [XX.XX])
\end{itemize}

The results indicate substantial improvements in both pixel-level accuracy (PSNR) and perceptual quality (SSIM, LPIPS), while the FID score demonstrates the model's ability to generate realistic images that are statistically similar to the training distribution.

\subsubsection{3D OASIS Volume Super-Resolution}

The 3D extension presents unique challenges due to the increased computational complexity and the need to maintain spatial consistency across all three dimensions. Our 3D wavelet decomposition approach addresses these challenges effectively.

\textbf{Performance Metrics:}
\begin{itemize}
\item PSNR: [XX.XX] dB (baseline: [XX.XX] dB)
\item SSIM: [0.XXXX] (baseline: [0.XXXX])
\item LPIPS: [0.XXXX] (baseline: [0.XXXX])
\item FID: [XX.XX] (baseline: [XX.XX])
\end{itemize}

The 3D results demonstrate that our approach successfully scales to volumetric data while maintaining high reconstruction quality. The integration of 3D attention mechanisms enables the model to capture long-range dependencies that are crucial for maintaining anatomical consistency.

\subsection{Computational Efficiency Analysis}

The integration of wavelet decomposition provides significant computational advantages, particularly for 3D processing where memory requirements can be prohibitive.

\textbf{Memory Usage:}
\begin{itemize}
\item Standard 3D processing: [XX] GB GPU memory
\item Wavelet-based processing: [XX] GB GPU memory
\item Memory reduction: [XX]\% through subband processing
\end{itemize}

\textbf{Training Efficiency:}
\begin{itemize}
\item Training time per epoch: [XX] hours (3D volumes)
\item Inference time per volume: [XX] seconds
\item Speedup compared to full 3D convolutions: [XX]x
\end{itemize}

The computational efficiency gains are particularly pronounced for 3D volumes, where the wavelet decomposition allows for processing of larger volumes that would otherwise exceed GPU memory limitations.

% Acknowledgments---Will not appear in anonymized version
\midlacknowledgments{We thank a bunch of people.}

\bibliography{midl-samplebibliography}

\end{document}
